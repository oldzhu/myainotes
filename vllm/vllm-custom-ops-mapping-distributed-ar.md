# vLLM custom ops mapping table: distributed + all-reduce stage

[English](vllm-custom-ops-mapping-distributed-ar.md) | [Chinese (ZH-CN)](vllm-custom-ops-mapping-distributed-ar.zh-CN.md)

Scope: device communication ops for custom GPU all-reduce and CPU shared-memory collectives.

## Mapping table: distributed + all-reduce ops

| Op | Python call site(s) + GPT inference role | Native implementation + notes/pseudo code |
|---|---|---|
| `init_custom_ar` | Called in custom all-reduce init [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L194). Role: create custom all-reduce context and initialize IPC buffers. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L13). Allocates communication handles and sets up topology. Pseudocode: `ctx = new CustomAR(handles)`.
| `register_buffer` | Called after init [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L197). Role: register per-rank IPC buffers for fast all-reduce. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L113). Stores IPC pointers in the context. Pseudocode: `ctx.register_buffer(ipc_ptrs)`.
| `get_graph_buffer_ipc_meta` | Called before graph capture [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L215). Role: export buffer handles/offsets for CUDA graph usage. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L125). Returns IPC handle and offsets. Pseudocode: `handle, offsets = ctx.get_graph_buffer_ipc_meta()`.
| `register_graph_buffers` | Called during graph setup [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L231). Role: register graph buffers for all-reduce in CUDA graph mode. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L133). Records graph buffer metadata. Pseudocode: `ctx.register_graph_buffers(handles, offsets)`.
| `all_reduce` | Called during collective [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L260). Role: perform custom all-reduce on a tensor. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L62). Launches the custom all-reduce kernel. Pseudocode: `custom_all_reduce(inp, out, world_size)`.
| `allocate_shared_buffer_and_handle` | Called in graph setup [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L302). Role: allocate a shared IPC buffer and export a handle. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L146). Returns a pointer and IPC handle. Pseudocode: `ptr, handle = alloc_shared(size)`.
| `open_mem_handle` | Called when opening IPC handles [vllm/vllm/distributed/device_communicators/custom_all_reduce.py](vllm/vllm/distributed/device_communicators/custom_all_reduce.py#L314). Role: open a CUDA IPC memory handle into a local pointer. | CUDA/C++ entry in [vllm/csrc/custom_all_reduce.cu](vllm/csrc/custom_all_reduce.cu#L179). Pseudocode: `ptr = open_mem_handle(handle)`.
| `init_shm_manager` | Called in CPU communicator setup [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L219). Role: create a shared-memory manager for CPU collectives. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L856). Creates shared-memory control structures. Pseudocode: `handle = shm_init(name, group_size)`.
| `join_shm_manager` | Called by non-leader ranks [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L226). Role: join an existing shared-memory manager. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L862). Pseudocode: `join(handle, name)`.
| `shm_allreduce` | Called in CPU communicator [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L237). Role: shared-memory all-reduce across CPU ranks. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L828). Performs sum-reduction in shared memory. Pseudocode: `sum_reduce(ctx, tensor)`.
| `shm_gather` | Called in CPU communicator [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L247). Role: gather tensors from all ranks into output buffers. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L777). Pseudocode: `gather(ctx, data, dst)`.
| `shm_all_gather` | Called in CPU communicator [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L260). Role: all-gather tensors across ranks. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L803). Pseudocode: `all_gather(ctx, data, output)`.
| `shm_send_tensor_list` | Called in CPU communicator [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L279). Role: send a list of tensors to a destination rank via shared memory. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L838). Pseudocode: `send_list(ctx, tensors, dst)`.
| `shm_recv_tensor_list` | Called in CPU communicator [vllm/vllm/distributed/device_communicators/cpu_communicator.py](vllm/vllm/distributed/device_communicators/cpu_communicator.py#L287). Role: receive a list of tensors from a source rank via shared memory. | CPU entry in [vllm/csrc/cpu/shm.cpp](vllm/csrc/cpu/shm.cpp#L848). Pseudocode: `tensors = recv_list(ctx, src)`.
